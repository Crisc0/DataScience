{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/rosinality/stylegan2-pytorch\n",
    "!git clone https://github.com/dvschultz/stylegan2-ada\n",
    "!pip install ninja #required dependency for stylegan2-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import utils\n",
    "\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "\n",
    "def convert_modconv(vars, source_name, target_name, flip=False):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    mod_weight = vars[source_name + '/mod_weight'].value().eval()\n",
    "    mod_bias = vars[source_name + '/mod_bias'].value().eval()\n",
    "    noise = vars[source_name + '/noise_strength'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {\n",
    "        'conv.weight': np.expand_dims(weight.transpose((3, 2, 0, 1)), 0),\n",
    "        'conv.modulation.weight': mod_weight.transpose((1, 0)),\n",
    "        'conv.modulation.bias': mod_bias + 1,\n",
    "        'noise.weight': np.array([noise]),\n",
    "        'activate.bias': bias,\n",
    "    }\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    if flip:\n",
    "        dic_torch[target_name + '.conv.weight'] = torch.flip(\n",
    "            dic_torch[target_name + '.conv.weight'], [3, 4]\n",
    "        )\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_conv(vars, source_name, target_name, bias=True, start=0):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "\n",
    "    dic = {'weight': weight.transpose((3, 2, 0, 1))}\n",
    "\n",
    "    if bias:\n",
    "        dic['bias'] = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    dic_torch[target_name + f'.{start}.weight'] = torch.from_numpy(dic['weight'])\n",
    "\n",
    "    if bias:\n",
    "        dic_torch[target_name + f'.{start + 1}.bias'] = torch.from_numpy(dic['bias'])\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_torgb(vars, source_name, target_name):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    mod_weight = vars[source_name + '/mod_weight'].value().eval()\n",
    "    mod_bias = vars[source_name + '/mod_bias'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {\n",
    "        'conv.weight': np.expand_dims(weight.transpose((3, 2, 0, 1)), 0),\n",
    "        'conv.modulation.weight': mod_weight.transpose((1, 0)),\n",
    "        'conv.modulation.bias': mod_bias + 1,\n",
    "        'bias': bias.reshape((1, 3, 1, 1)),\n",
    "    }\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_dense(vars, source_name, target_name):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {'weight': weight.transpose((1, 0)), 'bias': bias}\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def update(state_dict, new):\n",
    "    for k, v in new.items():\n",
    "        if k not in state_dict:\n",
    "            raise KeyError(k + ' is not found')\n",
    "\n",
    "        if v.shape != state_dict[k].shape:\n",
    "            raise ValueError(f'Shape mismatch: {v.shape} vs {state_dict[k].shape}')\n",
    "\n",
    "        state_dict[k] = v\n",
    "\n",
    "\n",
    "def discriminator_fill_statedict(statedict, vars, size):\n",
    "    log_size = int(math.log(size, 2))\n",
    "\n",
    "    update(statedict, convert_conv(vars, f'{size}x{size}/FromRGB', 'convs.0'))\n",
    "\n",
    "    conv_i = 1\n",
    "\n",
    "    for i in range(log_size - 2, 0, -1):\n",
    "        reso = 4 * 2 ** i\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(vars, f'{reso}x{reso}/Conv0', f'convs.{conv_i}.conv1'),\n",
    "        )\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(\n",
    "                vars, f'{reso}x{reso}/Conv1_down', f'convs.{conv_i}.conv2', start=1\n",
    "            ),\n",
    "        )\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(\n",
    "                vars, f'{reso}x{reso}/Skip', f'convs.{conv_i}.skip', start=1, bias=False\n",
    "            ),\n",
    "        )\n",
    "        conv_i += 1\n",
    "\n",
    "    update(statedict, convert_conv(vars, f'4x4/Conv', 'final_conv'))\n",
    "    update(statedict, convert_dense(vars, f'4x4/Dense0', 'final_linear.0'))\n",
    "    update(statedict, convert_dense(vars, f'Output', 'final_linear.1'))\n",
    "\n",
    "    return statedict\n",
    "\n",
    "\n",
    "def fill_statedict(state_dict, vars, size):\n",
    "    log_size = int(math.log(size, 2))\n",
    "\n",
    "    for i in range(8):\n",
    "        update(state_dict, convert_dense(vars, f'G_mapping/Dense{i}', f'style.{i + 1}'))\n",
    "\n",
    "    update(\n",
    "        state_dict,\n",
    "        {\n",
    "            'input.input': torch.from_numpy(\n",
    "                vars['G_synthesis/4x4/Const/const'].value().eval()\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    update(state_dict, convert_torgb(vars, 'G_synthesis/4x4/ToRGB', 'to_rgb1'))\n",
    "\n",
    "    for i in range(log_size - 2):\n",
    "        reso = 4 * 2 ** (i + 1)\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_torgb(vars, f'G_synthesis/{reso}x{reso}/ToRGB', f'to_rgbs.{i}'),\n",
    "        )\n",
    "\n",
    "    update(state_dict, convert_modconv(vars, 'G_synthesis/4x4/Conv', 'conv1'))\n",
    "\n",
    "    conv_i = 0\n",
    "\n",
    "    for i in range(log_size - 2):\n",
    "        reso = 4 * 2 ** (i + 1)\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_modconv(\n",
    "                vars,\n",
    "                f'G_synthesis/{reso}x{reso}/Conv0_up',\n",
    "                f'convs.{conv_i}',\n",
    "                flip=True,\n",
    "            ),\n",
    "        )\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_modconv(\n",
    "                vars, f'G_synthesis/{reso}x{reso}/Conv1', f'convs.{conv_i + 1}'\n",
    "            ),\n",
    "        )\n",
    "        conv_i += 2\n",
    "\n",
    "    for i in range(0, (log_size - 2) * 2 + 1):\n",
    "        update(\n",
    "            state_dict,\n",
    "            {\n",
    "                f'noises.noise_{i}': torch.from_numpy(\n",
    "                    vars[f'G_synthesis/noise{i}'].value().eval()\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print('Using PyTorch device', device)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--repo', type=str, required=True)\n",
    "    parser.add_argument('--gen', action='store_true')\n",
    "    parser.add_argument('--disc', action='store_true')\n",
    "    parser.add_argument('--channel_multiplier', type=int, default=2)\n",
    "    parser.add_argument('path', metavar='PATH')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    sys.path.append(args.repo)\n",
    "\n",
    "    import dnnlib\n",
    "    from dnnlib import tflib\n",
    "\n",
    "    tflib.init_tf()\n",
    "\n",
    "    with open(args.path, 'rb') as f:\n",
    "        generator, discriminator, g_ema = pickle.load(f)\n",
    "\n",
    "    size = g_ema.output_shape[2]\n",
    "\n",
    "    g = Generator(size, 512, 8, channel_multiplier=args.channel_multiplier)\n",
    "    state_dict = g.state_dict()\n",
    "    state_dict = fill_statedict(state_dict, g_ema.vars, size)\n",
    "\n",
    "    g.load_state_dict(state_dict)\n",
    "\n",
    "    latent_avg = torch.from_numpy(g_ema.vars['dlatent_avg'].value().eval())\n",
    "\n",
    "    ckpt = {'g_ema': state_dict, 'latent_avg': latent_avg}\n",
    "\n",
    "    if args.gen:\n",
    "        g_train = Generator(size, 512, 8, channel_multiplier=args.channel_multiplier)\n",
    "        g_train_state = g_train.state_dict()\n",
    "        g_train_state = fill_statedict(g_train_state, generator.vars, size)\n",
    "        ckpt['g'] = g_train_state\n",
    "\n",
    "    if args.disc:\n",
    "        disc = Discriminator(size, channel_multiplier=args.channel_multiplier)\n",
    "        d_state = disc.state_dict()\n",
    "        d_state = discriminator_fill_statedict(d_state, discriminator.vars, size)\n",
    "        ckpt['d'] = d_state\n",
    "\n",
    "    name = os.path.splitext(os.path.basename(args.path))[0]\n",
    "    outpath = os.path.join(os.getcwd(), f'{name}.pt')\n",
    "    print('Saving', outpath)\n",
    "    try:\n",
    "        torch.save(ckpt, outpath, _use_new_zipfile_serialization=False)\n",
    "    except TypeError:\n",
    "        torch.save(ckpt, outpath)\n",
    "    \n",
    "\n",
    "    print('Generating TF-Torch comparison images')\n",
    "    batch_size = {256: 8, 512: 4, 1024: 2}\n",
    "    n_sample = batch_size.get(size, 4)\n",
    "\n",
    "    g = g.to(device)\n",
    "\n",
    "    z = np.random.RandomState(0).randn(n_sample, 512).astype('float32')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_pt, _ = g(\n",
    "            [torch.from_numpy(z).to(device)],\n",
    "            truncation=0.5,\n",
    "            truncation_latent=latent_avg.to(device),\n",
    "        )\n",
    "\n",
    "    img_tf = g_ema.run(z, None, randomize_noise=False)\n",
    "    img_tf = torch.from_numpy(img_tf).to(device)\n",
    "\n",
    "    img_diff = ((img_pt + 1) / 2).clamp(0.0, 1.0) - ((img_tf.to(device) + 1) / 2).clamp(\n",
    "        0.0, 1.0\n",
    "    )\n",
    "\n",
    "    img_concat = torch.cat((img_tf, img_pt, img_diff), dim=0)\n",
    "    utils.save_image(\n",
    "        img_concat, name + '.png', nrow=n_sample, normalize=True, range=(-1, 1)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f830a0b92f9402ada73ab18b791d0d56a17bcb95f2d2c2d8f192cc2d1d3ea08b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
