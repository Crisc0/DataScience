{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import bck_adq\n",
    "from motpy import Detection, MultiObjectTracker\n",
    "from csv import writer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixColor(image):\n",
    "    return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path='trial.mp4'\n",
    "path='pichilemu\\pichilemu6224201-2.mp4'\n",
    "video_stream= cv2.VideoCapture(path)\n",
    "total_frames=video_stream.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeep_sort_realtime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeepsort_tracker\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepSort\n\u001b[0;32m      2\u001b[0m tracker \u001b[39m=\u001b[39m DeepSort(max_age\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m bbs \u001b[39m=\u001b[39m object_tracking\u001b[39m.\u001b[39;49mdetect(frame) \n\u001b[0;32m      4\u001b[0m tracks \u001b[39m=\u001b[39m tracker\u001b[39m.\u001b[39mupdate_tracks(bbs, frame\u001b[39m=\u001b[39mframe) \u001b[39m# bbs expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m track \u001b[39min\u001b[39;00m tracks:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'detect'"
     ]
    }
   ],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "tracker = DeepSort(max_age=5)\n",
    "bbs = object_tracking.detect(frame) \n",
    "tracks = tracker.update_tracks(bbs, frame=frame) # bbs expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\n",
    "for track in tracks:\n",
    "    if not track.is_confirmed():\n",
    "        continue\n",
    "    track_id = track.track_id\n",
    "    ltrb = track.to_ltrb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixColor(image):\n",
    "    return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path='trial.mp4'\n",
    "path='pichilemu\\pichilemu6224201-2.mp4'\n",
    "video_stream= cv2.VideoCapture(path)\n",
    "total_frames=video_stream.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8689.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for the result\n",
    "folderpath=path.split('.')[0]+' Dataset_v2'\n",
    "if not os.path.isdir(folderpath):\n",
    "   os.makedirs(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayMedianFrame= bck_adq.grayFrame(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    " \n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    " \n",
    "def createTrackerByName(trackerType):\n",
    "  # Create a tracker based on tracker name\n",
    "  if trackerType == trackerTypes[0]:\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "  elif trackerType == trackerTypes[1]:\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "  elif trackerType == trackerTypes[2]:\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "  elif trackerType == trackerTypes[3]:\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "  elif trackerType == trackerTypes[4]:\n",
    "    tracker = cv2.TrackerMedianFlow_create()\n",
    "  elif trackerType == trackerTypes[5]:\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "  elif trackerType == trackerTypes[6]:\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "  elif trackerType == trackerTypes[7]:\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "  else:\n",
    "    tracker = None\n",
    "    print('Incorrect tracker name')\n",
    "    print('Available trackers are:')\n",
    "    for t in trackerTypes:\n",
    "      print(t)\n",
    " \n",
    "  return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Object_tracking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tracker \u001b[39m=\u001b[39m DeepSort(max_age\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m bbs \u001b[39m=\u001b[39m Object_tracking\u001b[39m.\u001b[39mdetect(total_frames) \n\u001b[0;32m      3\u001b[0m tracks \u001b[39m=\u001b[39m tracker\u001b[39m.\u001b[39mupdate_tracks(bbs, frame\u001b[39m=\u001b[39mtotal_frames) \u001b[39m# bbs expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m track \u001b[39min\u001b[39;00m tracks:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Object_tracking' is not defined"
     ]
    }
   ],
   "source": [
    "tracker = DeepSort(max_age=5)\n",
    "bbs = object_tracking.detect(total_frames) \n",
    "tracks = tracker.update_tracks(bbs, frame=total_frames) # bbs expected to be a list of detections, each in tuples of ( [left,top,w,h], confidence, detection_class )\n",
    "for track in tracks:\n",
    "    if not track.is_confirmed():\n",
    "        continue\n",
    "    track_id = track.track_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = {\n",
    "        'order_pos': 1, 'dim_pos': 2, # position is a center in 2D space; under constant velocity model\n",
    "        'order_size': 0, 'dim_size': 2, # bounding box is 2 dimensional; under constant velocity model\n",
    "        'q_var_pos': 1000., # process noise\n",
    "        'r_var_pos': 0.1 # measurement noise\n",
    "    }\n",
    "tracker = DeepSort(max_age=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 0.011508804235239959% \r"
     ]
    }
   ],
   "source": [
    "frameCnt=0\n",
    "data=[]\n",
    "try:\n",
    "    while(frameCnt < total_frames-1):\n",
    "        ret, frame = video_stream.read()\n",
    "        #% of conversion\n",
    "        frameCnt+=1\n",
    "        print('Process: '+str(frameCnt/total_frames*100)+'% ',end=\"\\r\")\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate absolute difference of current frame and the median frame\n",
    "        dframe = cv2.absdiff(gframe, grayMedianFrame)\n",
    "\n",
    "        # Gaussian\n",
    "        blurred = cv2.GaussianBlur(dframe, (11, 11), 0)\n",
    "\n",
    "        #Thresholding to binarise\n",
    "        ret, tframe= cv2.threshold(blurred,0,255,\n",
    "                                   cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "        #Identifying contours from the threshold\n",
    "        (cnts, _) = cv2.findContours(tframe.copy(), \n",
    "                                     cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        if len(cnts) < 100:\n",
    "            #For each contour draw the bounding bos\n",
    "            for cnt in cnts:\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                tracker.step(detections=[Detection(box=np.array([int(x-w),int(y-h),int(x+2*w),int(y+2*h)]))])\n",
    "                tracks = tracker.active_tracks()\n",
    "                #cv2.rectangle(frame,(int(x-w),int(y-h)),(int(x+2*w),int(y+2*h)),(0,255,0),2)\n",
    "                #cv2.circle(frame, (int((x+x+w)/2),int((y+y+h)/2)),5,(0,0,255),5)\n",
    "                if len(tracks)>0:\n",
    "                    #cv2.putText(frame, tracks[0][0], (int(x-w),int(y-h-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "                    \n",
    "                    #['Frame','id','xmin','xmax','ymin','ymax']\n",
    "                    data.append([frameCnt,tracks[0][0],int(x-w), int(x+2*w),int(y-h),int(y+2*h)])\n",
    "            #Convert frames into png files\n",
    "            cv2.imwrite(os.path.join(folderpath,str(frameCnt)+'.png'),frame)\n",
    "\n",
    "\n",
    "        #Create video \n",
    "        #writer.write(cv2.resize(frame, (640,480)))\n",
    "\n",
    "    #Release video object\n",
    "    #video_stream.release()\n",
    "    #writer.release()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('KITAI_Dataset_2/test/_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(os.path.join(folderpath,'Data.csv'), 'w') \n",
    "writer = writer(file)\n",
    "writer.writerow(['Frame','id','xmin','xmax','ymin','ymax'])\n",
    "writer.writerows(data)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f830a0b92f9402ada73ab18b791d0d56a17bcb95f2d2c2d8f192cc2d1d3ea08b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
