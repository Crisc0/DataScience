{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a037324",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30c4b05398b76ae31150fcfd93208d76",
     "grade": false,
     "grade_id": "cell-2cbc8a748d55f7ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 3: Modelos de clasificación en presencia de clases desbalanceadas\n",
    "\n",
    "\n",
    "## ¡Bienvenido/a!\n",
    "\n",
    "Te invitamos a realizar el primer trabajo.\n",
    "- Objetivo: Para un caso práctico desarrollado en Python, aplicar diferentes técnicas de clasificación a un conjunto de datos con clases desbalanceadas, donde también se aplicarán diferentes alternativas para balancear las clases.\n",
    "- Tipo de actividad: Individual\n",
    "- Tipo de evaluación: Sumativa \n",
    "- Ponderación: 12%\n",
    "- Puntaje: 100 puntos\n",
    "- Calificación: Escala de 1 a 7, con una exigencia de 50%. La nota mínima para aprobar es 4.0.\n",
    "\n",
    "\n",
    "## Introducción:\n",
    "\n",
    "El objetivo de este laboratorio es explorar el uso de modelos de clasificación en presencia de clases desbalanceadas.\n",
    "Para esto, vamos a utilizar la base de datos `post_pabellon.csv`, la cual contiene datos de pacientes que fueron\n",
    "sometidos a una biopsia (extracción de tejido). La variable de interés es `HOSPITALIZACION`, la cual indica si el\n",
    "paciente fue hospitalizado luego de la biopsia. \n",
    "\n",
    "La siguiente tabla contiene la descripción de las variables (buscar información adicional en caso de considerarlo necesario) de la base de datos:\n",
    "\n",
    "|Variable|Descripción|Tipo|\n",
    "|--------|-----------|--|\n",
    "|EDAD|Edad del paciente| Numérica|\n",
    "|DIABETES|Indica si el paciente tiene o no diabetes| Binaria 1/0|\n",
    "|HOSPITALIZACIÓN ULTIMO MES|Indica si el paciente fue hospitalizado el mes previo al procedimiento| Binaria 1/0|\n",
    "|CUP|Uso de cateter urinario al momento de la biopsia| Binaria 1/0|\n",
    "|ENF. CRONICA PULMONAR OBSTRUCTIVA|Indica si el paciente tiene una efermedad crónica polmunar obstructuva| Binaria 1/0|\n",
    "|VOLUMEN PROSTATICO|Incica si el volumen prostatico es mayor a 40 $cm^3$| Binaria 1/0|\n",
    "|PSA| Concentración del antígeno prostático específico en la sangre| Numérica|\n",
    "|BIOPSIAS PREVIAS| Indica si el paciente ha tenido biopsias previas| Binaria 1/0|\n",
    "|ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS| Indica el tipo de antibiótico utilizado en la profilaxis| Categórica nominal |\n",
    "|NUMERO DE MUESTRAS TOMADAS| Número de muestras tomadas en la biopsia| Numérica|\n",
    "|BIOPSIA| Resultado de la biopsia| Binaria 1/0 (1: maligno, 0: benigno)|\n",
    "|HOSPITALIZACION| Indica si el paciente fue hospitalizado luego de la biopsia| Binaria 1/0|\n",
    "\n",
    "\n",
    "Los modelos que vamos a utilizar son los siguientes:\n",
    "- Support Vector Classifier (SVC)\n",
    "- Random Forest Classifier (RFC)\n",
    "- Naive Bayes Classifier (NBC)\n",
    "\n",
    "Además, vamos a utilizar las siguientes métricas para evaluar el ajuste y también medir el desempeño de los modelos (capacidad predictiva):\n",
    "- `Accuracy`: Porcentaje de casos correctamente clasificados sobre el total de casos.\n",
    "- `Precision`: Porcentaje de casos positivos correctamente clasificados sobre el total de casos clasificados como positivos.\n",
    "- `Recall`: Porcentaje de casos positivos correctamente clasificados sobre el total de casos positivos.\n",
    "- `F1-Score`: Media armónica entre Precision y Recall.\n",
    "- `AUC`: Área bajo la curva ROC.\n",
    "\n",
    "Por último, para equilibrar las clases vamos a utilizar las siguientes técnicas:\n",
    "- `RandomOverSampler`: Técnica de sobremuestreo que genera muestras sintéticas de la clase minoritaria.\n",
    "- `RandomUnderSampler`: Técnica de submuestreo que elimina muestras de la clase mayoritaria.\n",
    "- `NearMiss`: Técnica de submuestreo que elimina muestras de la clase mayoritaria basándonos en la distancia a las muestras de la clase minoritaria.\n",
    "- `ADASYN`: Técnica de sobremuestreo que genera muestras sintéticas de la clase minoritaria basándonos en la densidad de las muestras de la clase minoritaria.\n",
    "- Combinación de `RandomOverSampler` y `RandomUnderSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "565a4d99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed8b82dfb8cab302abcfd714f606c71f",
     "grade": false,
     "grade_id": "cell-daa87a6f414c3a46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Módulos básicos para análisis y manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Módulos para evaluación de modelos\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# Módulos para el balanceo de datos\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4504062",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68a7c33796d4c58a4b0db53beb2dab72",
     "grade": false,
     "grade_id": "cell-0e88d702ef11a00f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. Cargar la base de datos guardada en el archivo `post_pabellon.xlsx`, y guardar la data en el objeto `datos`. Luego, separar las variables de entrada en `X` y la variable respuesta en `y`. En el caso de las variables de entrada crear variables dummies para las variables categoricas nominales de más de dos niveles, para ello utilice la función `get_dummies` de la librería `pandas` con la opción `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a014a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_excel('post_pabellon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d904d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDAD</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HOSPITALIZACIÓN ULTIMO MES</th>\n",
       "      <th>PSA</th>\n",
       "      <th>BIOPSIAS PREVIAS</th>\n",
       "      <th>VOLUMEN PROSTATICO</th>\n",
       "      <th>ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS</th>\n",
       "      <th>NUMERO DE MUESTRAS TOMADAS</th>\n",
       "      <th>CUP</th>\n",
       "      <th>ENF. CRONICA PULMONAR OBSTRUCTIVA</th>\n",
       "      <th>BIOPSIA</th>\n",
       "      <th>HOSPITALIZACION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTROS</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CEFALOSPORINA_AMINOGLUCOCIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLUOROQUINOLONA_AMINOGLICOSIDO</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>OTROS</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDAD  DIABETES  HOSPITALIZACIÓN ULTIMO MES   PSA  BIOPSIAS PREVIAS  \\\n",
       "0      53         0                           0   4.0                 0   \n",
       "1      56         0                           0   7.7                 0   \n",
       "2      53         0                           0   7.0                 0   \n",
       "3      65         0                           0   4.3                 0   \n",
       "4      62         0                           0   7.0                 0   \n",
       "..    ...       ...                         ...   ...               ...   \n",
       "563    57         0                           0   4.8                 0   \n",
       "564    75         0                           0  75.0                 0   \n",
       "565    78         0                           0   9.3                 0   \n",
       "566    67         0                           0   6.0                 0   \n",
       "567    64         0                           0   4.8                 0   \n",
       "\n",
       "     VOLUMEN PROSTATICO ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS  \\\n",
       "0                     1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "1                     1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "2                     1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "3                     0          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "4                     1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "..                  ...                                     ...   \n",
       "563                   0                                   OTROS   \n",
       "564                   1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "565                   1            CEFALOSPORINA_AMINOGLUCOCIDO   \n",
       "566                   1          FLUOROQUINOLONA_AMINOGLICOSIDO   \n",
       "567                   1                                   OTROS   \n",
       "\n",
       "     NUMERO DE MUESTRAS TOMADAS  CUP  ENF. CRONICA PULMONAR OBSTRUCTIVA  \\\n",
       "0                            12    0                                  0   \n",
       "1                            12    0                                  0   \n",
       "2                            12    0                                  0   \n",
       "3                            12    0                                  0   \n",
       "4                            12    0                                  0   \n",
       "..                          ...  ...                                ...   \n",
       "563                          12    0                                  0   \n",
       "564                          12    0                                  0   \n",
       "565                          12    0                                  0   \n",
       "566                          12    0                                  0   \n",
       "567                          12    0                                  0   \n",
       "\n",
       "     BIOPSIA  HOSPITALIZACION  \n",
       "0          0                1  \n",
       "1          0                1  \n",
       "2          0                1  \n",
       "3          0                1  \n",
       "4          0                1  \n",
       "..       ...              ...  \n",
       "563        0                0  \n",
       "564        1                0  \n",
       "565        0                0  \n",
       "566        1                0  \n",
       "567        1                0  \n",
       "\n",
       "[568 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0af31",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44159f909778f1f3151f256f9792b4bf",
     "grade": false,
     "grade_id": "cell-c8b17ebb9f53f828",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "datos = None      # Variable que debe modificar\n",
    "y = None          # Variable que debe modificar\n",
    "X = None          # Variable que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fed9cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EDAD  DIABETES  HOSPITALIZACIÓN ULTIMO MES  PSA  BIOPSIAS PREVIAS  \\\n",
      "0    53         0                           0  4.0                 0   \n",
      "1    56         0                           0  7.7                 0   \n",
      "2    53         0                           0  7.0                 0   \n",
      "3    65         0                           0  4.3                 0   \n",
      "4    62         0                           0  7.0                 0   \n",
      "\n",
      "   VOLUMEN PROSTATICO  NUMERO DE MUESTRAS TOMADAS  CUP  \\\n",
      "0                   1                          12    0   \n",
      "1                   1                          12    0   \n",
      "2                   1                          12    0   \n",
      "3                   0                          12    0   \n",
      "4                   1                          12    0   \n",
      "\n",
      "   ENF. CRONICA PULMONAR OBSTRUCTIVA  BIOPSIA  \\\n",
      "0                                  0        0   \n",
      "1                                  0        0   \n",
      "2                                  0        0   \n",
      "3                                  0        0   \n",
      "4                                  0        0   \n",
      "\n",
      "   ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS_FLUOROQUINOLONA_AMINOGLICOSIDO  \\\n",
      "0                                                  1                        \n",
      "1                                                  1                        \n",
      "2                                                  1                        \n",
      "3                                                  1                        \n",
      "4                                                  1                        \n",
      "\n",
      "   ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS_OROQUINOLONAS  \\\n",
      "0                                                  0       \n",
      "1                                                  0       \n",
      "2                                                  0       \n",
      "3                                                  0       \n",
      "4                                                  0       \n",
      "\n",
      "   ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS_OTROS  \n",
      "0                                              0  \n",
      "1                                              0  \n",
      "2                                              0  \n",
      "3                                              0  \n",
      "4                                              0  \n",
      "0    544\n",
      "1     24\n",
      "Name: HOSPITALIZACION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datos = pd.read_excel('post_pabellon.xlsx')\n",
    "X = datos.drop(columns=['HOSPITALIZACION'])\n",
    "y = datos['HOSPITALIZACION']\n",
    "X = pd.get_dummies(X, columns=['ANTIBIOTICO UTILIAZADO EN LA PROFILAXIS'], drop_first=True)\n",
    "\n",
    "X.head()\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b553b87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a746b99a1fface9f6c887e1b0df5d3",
     "grade": true,
     "grade_id": "cell-743fcf61e6a2aa71",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P1: Prueba de la carga de la base de datos y de la creación de las variables de entrada y respuesta tal como se especifica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446ab93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38171f1a877add3de9fc9052d7bae615",
     "grade": false,
     "grade_id": "cell-375a2e0f241102e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. Realice una descomposición aleatoria estratificada según la variable respuesta con una proporción de 70% para entrenamiento y 30% para validación. Utilice una semilla de 123 para replicar los resultados.\n",
    "\n",
    "Debe entregar los siguientes objetos:\n",
    "- `X_train`: Matriz de predictores para entrenamiento.\n",
    "- `X_test`: Matriz de predictores para validación.\n",
    "- `y_train`: Vector de respuesta para entrenamiento.\n",
    "- `y_test`: Vector de respuesta para validación.\n",
    "\n",
    "**OBS**: Utilice la función `train_test_split` de la librería `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289f098",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10aa5bc0f0d843b81c809679785cc01d",
     "grade": false,
     "grade_id": "cell-a0f34c9421860115",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = None      # Variable que debe modificar\n",
    "y_train = None      # Variable que debe modificar\n",
    "\n",
    "X_test = None       # Variable que debe modificar\n",
    "y_test = None       # Variable que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd3ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (397, 13)\n",
      "X_test shape: (171, 13)\n",
      "y_train distribution:\n",
      "0    380\n",
      "1     17\n",
      "Name: HOSPITALIZACION, dtype: int64\n",
      "y_test distribution:\n",
      "0    164\n",
      "1      7\n",
      "Name: HOSPITALIZACION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"y_test distribution:\\n{y_test.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68511c7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7da2e5fcf604be761a58ef41d9f485d",
     "grade": true,
     "grade_id": "cell-820755a100962454",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P2: Prueba de dimensiones de los datos y aleatoriedad de la separación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69434e0f",
   "metadata": {},
   "source": [
    "3. A continuación, debe realizar una **validación cruzada estratificada** con 5 folds sobre la partición de entrenamiento para comparar diferentes modelos que \n",
    "se especificarán más adelante. \n",
    "\n",
    "Intrucciones:\n",
    "- Utilice la función `StratifiedKFold` del módulo `model_selection` de la librería `sklearn`. Este objeto debe ser entregado como argumento a la función `cross_val_score`.\n",
    "- Se debe utilizar el número 123 como semilla de aleatorización de la función `StratifiedKFold`. Además utilice el argumento `shuffle=True`.\n",
    "- Se deben evaluar las siguientes métricas de ajuste en cada fold: `accuracy`, `precision`, `recall`, `f1` y `roc_auc`.\n",
    "- El objetivo es comparar el desempeño de los modelos en cada fold, para esto, se debe calcular la **media** de cada métrica de ajuste por modelo.\n",
    "- Debe entregar un dataframe de nombre `cv_results` con la siguiente estructura:\n",
    "\n",
    "    | |Accuracy|Precision|Recall|F1|AUC|\n",
    "    |-|--------|---------|------|--|-------|\n",
    "    |SV|-|-|-|-|-|\n",
    "    |RF|-|-|-|-|-|\n",
    "    |NB|-|-|-|-|-|\n",
    "\n",
    "    En python:\n",
    "        \n",
    "    ```python\n",
    "    # Dataframe vacío\n",
    "    cv_results = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "    ```\n",
    "- Los modelos deben considerar todas las variables de la base de datos y utilizar los siguientes hiperparámetros:\n",
    "    - SVC: `C=15`, `kernel='poly'`, `degree=2`\n",
    "    - RFC: `n_estimators=50`, `max_depth=10`, `random_state=123`, `max_samples=0.8`, `max_features='log2'`\n",
    "    - NBC: `class_prior=[0.5, 0.5]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773bf0c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bcbe278de57bce59ba8d89255e7c426",
     "grade": false,
     "grade_id": "cell-216c3278ad55e19a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Modelos que debe ajustar\n",
    "\n",
    "SVC_model = SVC(C=15, kernel='poly', degree=2)\n",
    "RF_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "NB_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771dbaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.957215       0.0       0.0       0.0  0.735307\n",
      "RF  0.959747       0.3  0.133333      0.18  0.855702\n",
      "NB  0.838829  0.051496  0.183333  0.078941  0.619408\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(C=15, kernel='poly', degree=2, random_state=123)\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "nb_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "def metricas(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=skf, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=skf, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring='f1').mean()\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring='roc_auc').mean()\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "cv_results.loc['SV'] = metricas(svc_model, X_train, y_train)\n",
    "cv_results.loc['RF'] = metricas(rf_model, X_train, y_train)\n",
    "cv_results.loc['NB'] = metricas(nb_model, X_train, y_train)\n",
    "print(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4f3d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>0.957215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.959747</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.855702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.838829</td>\n",
       "      <td>0.051496</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.078941</td>\n",
       "      <td>0.619408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Precision    Recall        F1       AUC\n",
       "SV  0.957215       0.0       0.0       0.0  0.735307\n",
       "RF  0.959747       0.3  0.133333      0.18  0.855702\n",
       "NB  0.838829  0.051496  0.183333  0.078941  0.619408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4587df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab8277156d24507abb945ddd16712655",
     "grade": true,
     "grade_id": "cell-db486fa44ed240d1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P3: Se comparan los valores de la matriz cv_results completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c39d20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c8aa15d90734ae75c034277da627d07",
     "grade": false,
     "grade_id": "cell-76af06b283d2e505",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "4. De acuerdo con los resultados anteriores, ¿cuál modelo recomedaría?. \n",
    "\n",
    "Para ello primero debe indicar la medida de desempeño en `medida`, donde debe escoger entre 'Accuracy', 'Precision', 'F1', 'Recall' y 'AUC'. (Por ejemplo, `medida='Accuracy'`). Una vez seleccionada la medida debe indicar el modelo de mejor desempeño, de acuerdo con la validación cruzada, en el objeto `model_select`, para indicar el mejor modelo utilizar `SV`, `RF` o `NB` (Por ejemplo, `model_select='SV'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19524ed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8415af5bd68679273a2fa826e35ea9c",
     "grade": false,
     "grade_id": "cell-82a96fe373bcb2cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "medida = None            # Variable que debe modificar\n",
    "model_select = None      # Variable que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "medida = 'AUC'  \n",
    "model_select = 'RF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0eb30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "112da8ef203d0f24715137785a5924cd",
     "grade": true,
     "grade_id": "cell-ecefd55f6e9b2f6a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P4: Elección adecuada del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda158e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b58625f6a62527bc1ee051c9b1b5a46d",
     "grade": false,
     "grade_id": "cell-72f764a9ace91db2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "5. También se debe evaluar el desempeño de los modelos, es decir, su capacidad predictiva o de generalización. Tener en cuenta, que por lo general, se debe evaluar solo la generalización del modelo escogido con la muestra de entrenamiento, cuando este último se considera aceptable. Solo con fines comparativos se evaluará la generalización de los 3 modelos propuestos.\n",
    "\n",
    "\n",
    "Para esto, ajuste los modelos del punto anterior con los datos de entrenamiento y evalúelos con los datos de validación. Debe entregar un dataframe de nombre `test_results` con la siguiente estructura:\n",
    "\n",
    "| |Accuracy|Precision|Recall|F1|AUC|\n",
    "|-|--------|---------|------|--|-------|\n",
    "|SV|-|-|-|-|-|\n",
    "|RF|-|-|-|-|-|\n",
    "|NB|-|-|-|-|-|\n",
    "\n",
    "En python:\n",
    "    \n",
    "```python\n",
    "# Dataframe vacío\n",
    "test_results = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "```\n",
    "\n",
    "Considere los mismos hiperparámetros del punto anterior. En caso de división por cero se debe deja el indicar (o métrica) en 0, para ello utilice el argumente `zero_division=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624dd1a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba84a31ccc889d07007bf2ac352fd086",
     "grade": false,
     "grade_id": "cell-9baf55742293fcb1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4616ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.891115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.729094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy Precision    Recall        F1       AUC\n",
       "SV  0.959064       0.0       0.0       0.0  0.719512\n",
       "RF  0.959064       0.0       0.0       0.0  0.891115\n",
       "NB  0.853801  0.090909  0.285714  0.137931  0.729094"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "svc = SVC(C=15, kernel='poly', degree=2, random_state=123)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "test_results.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc.decision_function(X_test))  \n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "test_results.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rfc.predict_proba(X_test)[:, 1])  \n",
    "\n",
    "nbc = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "nbc.fit(X_train, y_train)\n",
    "y_pred_nbc = nbc.predict(X_test)\n",
    "\n",
    "test_results.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nbc.predict_proba(X_test)[:, 1])  \n",
    "\n",
    "test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3631a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61c626957bac8039d03ab58f5a95d8c3",
     "grade": true,
     "grade_id": "cell-724229057677d869",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P5: Se comparan los valores de la matriz test_results completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ec1e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43380e44bbf64c164ae64c71323632f5",
     "grade": false,
     "grade_id": "cell-d476a12fa30f4d9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hasta ahora, hemos trabajado con los datos \"originales\", es decir, sin balancear las clases. Lo que produce este problema es la inclinación de los modelos a prever la clase mayoritaria, resultando en un rendimiento deficiente. Para solucionar esto, vamos a utilizar las técnicas de remuestreo mencionadas en la introducción del laboratorio.\n",
    "\n",
    "Además, habrá notado que la métricas: `precision` y `recall` no han tenido un buen desempeño en los modelos anteriores. Esto se debe a que estas métricas están relacionadas con la clase minoritaria. Luego, para mejorar el desempeño de estas métricas, debemos balancear las clases.\n",
    "\n",
    "Las siguientes preguntas tienen como propósito evaluar el rendimiento de los modelos previos utilizando datos balanceados. **Aunque es posible que cada modelo mejore con ajustes más precisos, el enfoque de este laboratorio es analizar el comportamiento de los modelos al equilibrar las clases con las diferentes técnicas disponibles**.\n",
    "\n",
    "**MUY IMPORTANTE**: para las preguntas 6, 7 y 8 debe entregar los dataframes con el mismo formato anterior, es decir:\n",
    "\n",
    "| |Accuracy|Precision|Recall|F1|AUC|\n",
    "|-|--------|---------|------|--|-------|\n",
    "|SV|-|-|-|-|-|\n",
    "|RF|-|-|-|-|-|\n",
    "|NB|-|-|-|-|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b6310",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5979b3f2f1ecb0693572ba788b60b1ef",
     "grade": false,
     "grade_id": "cell-9b8ef3d9ca85dd71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "6 - Realice un sobremuestreo de la clase minoritaria utilizando la técnica `RandomOverSampler` y evalúe el desempeño de los modelos con los datos balanceados. Debe replicar lo solicitado en el punto 3 y 5, pero ahora con los datos balanceados. Debe entregar los siguientes objetos:\n",
    "\n",
    "- `cv_results_balanced`: Dataframe con los resultados de la validación cruzada estratificada con 5 folds.\n",
    "- `test_results_balanced`: Dataframe con los resultados de la evaluación de los modelos con los datos de validación.\n",
    "\n",
    "Considere utilizar los siguientes hiperparámetros: `random_state=123` y `sampling_strategy='minority'` en `RandomOverSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dea247",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0a0ac52b3b1374e4e39d1135bac45e2",
     "grade": false,
     "grade_id": "cell-0d16ed06e92eb8e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "753c7693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación cruzada datos balanceados (random_over):\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.651316  0.589147       1.0  0.741463  0.690218\n",
      "RF  0.988158  0.976864       1.0  0.988296  0.998792\n",
      "NB  0.664474  0.648456  0.718421  0.681648   0.74893\n",
      "\n",
      "Resultados de la evaluación con el conjunto de validación datos balanceados (random_over):\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.058824       1.0  0.111111  0.848432\n",
      "RF  0.953216  0.428571  0.428571  0.428571  0.857143\n",
      "NB  0.555556      0.04  0.428571  0.073171  0.642857\n"
     ]
    }
   ],
   "source": [
    "random_over = RandomOverSampler(random_state=123, sampling_strategy='minority')\n",
    "X_train_balanced, y_train_balanced = random_over.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results_balanced = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "modelos = {\n",
    "    'SV': SVC(C=15, kernel='poly', degree=2, random_state=123, probability=True),\n",
    "    'RF': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2'),\n",
    "    'NB': BernoulliNB(class_prior=[0.5, 0.5])\n",
    "}\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    y_pred = np.zeros(y_train_balanced.shape)\n",
    "    y_proba = np.zeros((y_train_balanced.shape[0], 2))\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_balanced, y_train_balanced):\n",
    "        X_train_fold, X_val_fold = X_train_balanced.iloc[train_index], X_train_balanced.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_balanced.iloc[train_index], y_train_balanced.iloc[val_index]\n",
    "        modelo.fit(X_train_fold, y_train_fold)\n",
    "        y_pred[val_index] = modelo.predict(X_val_fold)\n",
    "        y_proba[val_index] = modelo.predict_proba(X_val_fold)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_train_balanced, y_pred)\n",
    "    precision = metrics.precision_score(y_train_balanced, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_train_balanced, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_train_balanced, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_train_balanced, y_proba[:, 1])\n",
    "\n",
    "    cv_results_balanced.loc[nombre_modelo, 'Accuracy'] = accuracy\n",
    "    cv_results_balanced.loc[nombre_modelo, 'Precision'] = precision\n",
    "    cv_results_balanced.loc[nombre_modelo, 'Recall'] = recall\n",
    "    cv_results_balanced.loc[nombre_modelo, 'F1'] = f1\n",
    "    cv_results_balanced.loc[nombre_modelo, 'AUC'] = auc\n",
    "\n",
    "test_results_balanced = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    modelo.fit(X_train_balanced, y_train_balanced)\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = metrics.precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = metrics.recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = metrics.f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = metrics.roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    test_results_balanced.loc[nombre_modelo, 'Accuracy'] = test_accuracy\n",
    "    test_results_balanced.loc[nombre_modelo, 'Precision'] = test_precision\n",
    "    test_results_balanced.loc[nombre_modelo, 'Recall'] = test_recall\n",
    "    test_results_balanced.loc[nombre_modelo, 'F1'] = test_f1\n",
    "    test_results_balanced.loc[nombre_modelo, 'AUC'] = test_auc\n",
    "\n",
    "print(\"Resultados de la validación cruzada datos balanceados (random_over):\")\n",
    "print(cv_results_balanced)\n",
    "\n",
    "print(\"\\nResultados de la evaluación con el conjunto de validación datos balanceados (random_over):\")\n",
    "print(test_results_balanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168a606",
   "metadata": {},
   "source": [
    "### copilot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ea61d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.651316  0.589468       1.0  0.741624  0.691118\n",
      "RF  0.988158  0.976954       1.0   0.98832  0.998979\n",
      "NB  0.664474  0.650265  0.718421  0.682299  0.757185\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.058824       1.0  0.111111  0.848432\n",
      "RF  0.953216  0.428571  0.428571  0.428571  0.857143\n",
      "NB  0.555556      0.04  0.428571  0.073171  0.642857\n"
     ]
    }
   ],
   "source": [
    "random_over = RandomOverSampler(random_state=123, sampling_strategy='minority')\n",
    "X_resampled, y_resampled = random_over.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results_balanced = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "def metricas(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=skf, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=skf, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring='f1').mean()\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring='roc_auc').mean()\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "svc_model = SVC(C=15, kernel='poly', degree=2, random_state=123)\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "nb_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "\n",
    "cv_results_balanced.loc['SV'] = metricas(svc_model, X_resampled, y_resampled)\n",
    "cv_results_balanced.loc['RF'] = metricas(rf_model, X_resampled, y_resampled)\n",
    "cv_results_balanced.loc['NB'] = metricas(nb_model, X_resampled, y_resampled)\n",
    "\n",
    "print(cv_results_balanced)\n",
    "\n",
    "test_results_balanced = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "\n",
    "svc_model.fit(X_resampled, y_resampled)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "\n",
    "test_results_balanced.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results_balanced.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc_model.decision_function(X_test))\n",
    "\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "y_pred_rfc = rf_model.predict(X_test)\n",
    "\n",
    "test_results_balanced.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results_balanced.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "nb_model.fit(X_resampled, y_resampled)\n",
    "y_pred_nbc = nb_model.predict(X_test)\n",
    "\n",
    "test_results_balanced.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results_balanced.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(test_results_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f68c36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e64cc084eab03050c93f3d49df348a8c",
     "grade": true,
     "grade_id": "cell-dbb8b90e472f001c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P6: Se comparan los valores de la matriz cv_results_balanced completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685478e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbf8617bc1e5f369423b1f45a172e2b0",
     "grade": true,
     "grade_id": "cell-e37b05a2717cf9bb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 2 - P6: Se comparan los valores de la matriz test_results_balanced completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae8e0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff422b9a66202e481823c52795ed667b",
     "grade": false,
     "grade_id": "cell-961444add5159a79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "7 - Nuevamente realice la validación cruzada y la evaluación del conjunto de prueba para los modelos de clasificación, pero esta vez utilizando la técnica `RandomUnderSampler` para balancear las clases. Debe entregar los siguientes objetos:\n",
    "\n",
    "- `cv_results_balanced2`: Dataframe con los resultados de la validación cruzada estratificada con 5 folds.\n",
    "- `test_results_balanced2`: Dataframe con los resultados de la evaluación de los modelos con los datos de validación.\n",
    "\n",
    "Considere utilizar los siguientes hiperparámetros: `random_state=123` y `sampling_strategy='majority'` en `RandomUnderSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6039f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffbdc0da2d9c5a6ca8711d29e35b3b5d",
     "grade": false,
     "grade_id": "cell-cea58033167ef7ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a5b7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación cruzada datos balanceados (random_under):\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.470588  0.470588  0.470588  0.470588  0.557093\n",
      "RF  0.617647  0.590909  0.764706  0.666667  0.631488\n",
      "NB  0.382353  0.409091  0.529412  0.461538  0.224913\n",
      "\n",
      "Resultados de la evaluación con el conjunto de validación datos balanceados (random_under):\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.051282  0.857143  0.096774  0.454704\n",
      "RF  0.777778  0.121951  0.714286  0.208333  0.791812\n",
      "NB  0.526316  0.059524  0.714286   0.10989   0.70122\n"
     ]
    }
   ],
   "source": [
    "random_under = RandomUnderSampler(random_state=123, sampling_strategy='majority')\n",
    "X_train_balanced2, y_train_balanced2 = random_under.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results_balanced2 = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "modelos = {\n",
    "    'SV': SVC(C=15, kernel='poly', degree=2, random_state=123, probability=True),\n",
    "    'RF': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2'),\n",
    "    'NB': BernoulliNB(class_prior=[0.5, 0.5])\n",
    "}\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    y_pred = np.zeros(y_train_balanced2.shape)\n",
    "    y_proba = np.zeros((y_train_balanced2.shape[0], 2))\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_balanced2, y_train_balanced2):\n",
    "        X_train_fold, X_val_fold = X_train_balanced2.iloc[train_index], X_train_balanced2.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_balanced2.iloc[train_index], y_train_balanced2.iloc[val_index]\n",
    "        modelo.fit(X_train_fold, y_train_fold)\n",
    "        y_pred[val_index] = modelo.predict(X_val_fold)\n",
    "        y_proba[val_index] = modelo.predict_proba(X_val_fold)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_train_balanced2, y_pred)\n",
    "    precision = metrics.precision_score(y_train_balanced2, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_train_balanced2, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_train_balanced2, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_train_balanced2, y_proba[:, 1])\n",
    "\n",
    "    cv_results_balanced2.loc[nombre_modelo, 'Accuracy'] = accuracy\n",
    "    cv_results_balanced2.loc[nombre_modelo, 'Precision'] = precision\n",
    "    cv_results_balanced2.loc[nombre_modelo, 'Recall'] = recall\n",
    "    cv_results_balanced2.loc[nombre_modelo, 'F1'] = f1\n",
    "    cv_results_balanced2.loc[nombre_modelo, 'AUC'] = auc\n",
    "\n",
    "test_results_balanced2 = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    modelo.fit(X_train_balanced2, y_train_balanced2)\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = metrics.precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = metrics.recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = metrics.f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = metrics.roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    test_results_balanced2.loc[nombre_modelo, 'Accuracy'] = test_accuracy\n",
    "    test_results_balanced2.loc[nombre_modelo, 'Precision'] = test_precision\n",
    "    test_results_balanced2.loc[nombre_modelo, 'Recall'] = test_recall\n",
    "    test_results_balanced2.loc[nombre_modelo, 'F1'] = test_f1\n",
    "    test_results_balanced2.loc[nombre_modelo, 'AUC'] = test_auc\n",
    "\n",
    "print(\"Resultados de la validación cruzada datos balanceados (random_under):\")\n",
    "print(cv_results_balanced2)\n",
    "\n",
    "print(\"\\nResultados de la evaluación con el conjunto de validación datos balanceados (random_under):\")\n",
    "print(test_results_balanced2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd632826",
   "metadata": {},
   "source": [
    "### copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a8abe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.466667  0.419048  0.483333  0.415238       0.4\n",
      "RF  0.609524  0.497619  0.733333  0.591169  0.616667\n",
      "NB   0.37619      0.42  0.516667  0.450794  0.236111\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.345029  0.051282  0.857143  0.096774  0.545296\n",
      "RF  0.777778  0.121951  0.714286  0.208333  0.791812\n",
      "NB  0.526316  0.059524  0.714286   0.10989   0.70122\n"
     ]
    }
   ],
   "source": [
    "random_under = RandomUnderSampler(random_state=123, sampling_strategy='majority')\n",
    "X_resampled, y_resampled = random_under.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results_balanced2 = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "def metricas(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=skf, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=skf, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring='f1').mean()\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring='roc_auc').mean()\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "svc_model = SVC(C=15, kernel='poly', degree=2, random_state=123)\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "nb_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "cv_results_balanced2.loc['SV'] = metricas(svc_model, X_resampled, y_resampled)\n",
    "cv_results_balanced2.loc['RF'] = metricas(rf_model, X_resampled, y_resampled)\n",
    "cv_results_balanced2.loc['NB'] = metricas(nb_model, X_resampled, y_resampled)\n",
    "\n",
    "print(cv_results_balanced2)\n",
    "\n",
    "test_results_balanced2 = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "svc_model.fit(X_resampled, y_resampled)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "\n",
    "test_results_balanced2.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results_balanced2.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced2.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced2.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced2.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc_model.decision_function(X_test))\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "y_pred_rfc = rf_model.predict(X_test)\n",
    "test_results_balanced2.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results_balanced2.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced2.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced2.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced2.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "nb_model.fit(X_resampled, y_resampled)\n",
    "y_pred_nbc = nb_model.predict(X_test)\n",
    "test_results_balanced2.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results_balanced2.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced2.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced2.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced2.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(test_results_balanced2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48739f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bda0cf9270c51381e8c4ad69ce538e4",
     "grade": true,
     "grade_id": "cell-fe10aaed377f01c8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P7: Se comparan los valores de la matriz cv_results_balanced2 completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17846248",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30b07f95260d2fdb732f65d3c1f28a5b",
     "grade": true,
     "grade_id": "cell-ce06e16b6ef3dc0e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 2 - P7: Se comparan los valores de la matriz test_results_balanced2 completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c511958",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c71a18b1ee8bd8f7bfb4c9c4dcf1711f",
     "grade": false,
     "grade_id": "cell-6cd0b86e004f5bae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "8 - Por último, nuevamente balancear las clases, pero esta vez utilizando las siguientes técnicas de balanceo de clases:\n",
    "- `NearMiss`\n",
    "- `ADASYN`\n",
    "- Combinación de `RandomOverSampler` y `RandomUnderSampler` con `sampling_strategy=0.5` en ambos.\n",
    "\n",
    "Los nombres de los objetos deben ser los siguientes:\n",
    "- `cv_results_balanced_nm`: Dataframe con los resultados de la validación cruzada estratificada con 5 folds utilizando `NearMiss`.\n",
    "- `test_results_balanced_nm`: Dataframe con los resultados de la evaluación de los modelos con los datos de validación utilizando `NearMiss`.\n",
    "- `cv_results_balanced_ad`: Dataframe con los resultados de la validación cruzada estratificada con 5 folds utilizando `ADASYN`.\n",
    "- `test_results_balanced_ad`: Dataframe con los resultados de la evaluación de los modelos con los datos de validación utilizando `ADASYN`.\n",
    "- `cv_results_balanced_comb`: Dataframe con los resultados de la validación cruzada estratificada con 5 folds utilizando `RandomOverSampler` y `RandomUnderSampler`.\n",
    "- `test_results_balanced_comb`: Dataframe con los resultados de la evaluación de los modelos con los datos de validación utilizando `RandomOverSampler` y `RandomUnderSampler`.\n",
    "\n",
    "Debe utilizar los siguientes hiperparámetros para cada técnica de balanceo:\n",
    "- `NearMiss`: `sampling_strategy='majority'`\n",
    "- `ADASYN`: `random_state=123`, `sampling_strategy='minority'`\n",
    "- `RandomOverSampler` y `RandomUnderSampler`: `random_state=123`, `sampling_strategy=0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad1ccc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d57de4fdd58bb8e5124ee37f8302467",
     "grade": false,
     "grade_id": "cell-e586df0c4c0281a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a3107d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación cruzada con NearMiss:\n",
      "    Accuracy Precision    Recall   F1       AUC\n",
      "SV  0.588235  0.636364  0.411765  0.5  0.422145\n",
      "RF  0.647059  0.692308  0.529412  0.6  0.614187\n",
      "NB  0.558824     0.625  0.294118  0.4  0.612457\n",
      "\n",
      "Resultados de la evaluación con NearMiss:\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.362573  0.044643  0.714286  0.084034  0.512195\n",
      "RF  0.467836  0.053191  0.714286   0.09901  0.665505\n",
      "NB  0.748538  0.071429  0.428571  0.122449  0.663763\n",
      "Resultados de la validación cruzada con ADASYN:\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV   0.57971  0.559289  0.746702  0.639548  0.676212\n",
      "RF  0.919631  0.927419   0.91029  0.918775  0.966664\n",
      "NB  0.760211  0.701431  0.905013  0.790323  0.792386\n",
      "\n",
      "Resultados de la evaluación con ADASYN:\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.432749  0.067308       1.0  0.126126  0.830139\n",
      "RF  0.894737  0.238095  0.714286  0.357143  0.844512\n",
      "NB   0.54386  0.050633  0.571429  0.093023  0.632404\n",
      "Resultados de la validación cruzada con combinación de random_over y random_under:\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.647059       0.0       0.0       0.0  0.410035\n",
      "RF  0.705882  0.555556  0.588235  0.571429  0.777682\n",
      "NB  0.490196      0.32  0.470588  0.380952  0.497405\n",
      "\n",
      "Resultados de la evaluación con combinación de random_over y random_under:\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.959064       0.0       0.0       0.0  0.301394\n",
      "RF  0.865497  0.192308  0.714286   0.30303  0.910279\n",
      "NB  0.567251  0.064935  0.714286  0.119048  0.734321\n"
     ]
    }
   ],
   "source": [
    "SV_model = SVC(C=15, kernel='poly', degree=2, random_state=123, probability=True)\n",
    "RF_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "NB_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "\n",
    "modelos = {\n",
    "    'SV': SV_model,\n",
    "    'RF': RF_model,\n",
    "    'NB': NB_model\n",
    "}\n",
    "\n",
    "modelos = {\n",
    "    'SV': SV_model,  \n",
    "    'RF': RF_model,  \n",
    "    'NB': NB_model   \n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "nearmiss = NearMiss(sampling_strategy='majority')\n",
    "X_train_balanced_nm, y_train_balanced_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "cv_results_balanced_nm = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    y_pred = np.zeros(y_train_balanced_nm.shape)\n",
    "    y_proba = np.zeros((y_train_balanced_nm.shape[0], 2))\n",
    "    for train_index, val_index in skf.split(X_train_balanced_nm, y_train_balanced_nm):\n",
    "        X_train_fold, X_val_fold = X_train_balanced_nm.iloc[train_index], X_train_balanced_nm.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_balanced_nm.iloc[train_index], y_train_balanced_nm.iloc[val_index]\n",
    "        modelo.fit(X_train_fold, y_train_fold)\n",
    "        y_pred[val_index] = modelo.predict(X_val_fold)\n",
    "        y_proba[val_index] = modelo.predict_proba(X_val_fold)\n",
    "    accuracy = metrics.accuracy_score(y_train_balanced_nm, y_pred)\n",
    "    precision = metrics.precision_score(y_train_balanced_nm, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_train_balanced_nm, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_train_balanced_nm, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_train_balanced_nm, y_proba[:, 1])\n",
    "    cv_results_balanced_nm.loc[nombre_modelo, 'Accuracy'] = accuracy\n",
    "    cv_results_balanced_nm.loc[nombre_modelo, 'Precision'] = precision\n",
    "    cv_results_balanced_nm.loc[nombre_modelo, 'Recall'] = recall\n",
    "    cv_results_balanced_nm.loc[nombre_modelo, 'F1'] = f1\n",
    "    cv_results_balanced_nm.loc[nombre_modelo, 'AUC'] = auc\n",
    "\n",
    "test_results_balanced_nm = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    modelo.fit(X_train_balanced_nm, y_train_balanced_nm)\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = metrics.precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = metrics.recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = metrics.f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = metrics.roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "    test_results_balanced_nm.loc[nombre_modelo, 'Accuracy'] = test_accuracy\n",
    "    test_results_balanced_nm.loc[nombre_modelo, 'Precision'] = test_precision\n",
    "    test_results_balanced_nm.loc[nombre_modelo, 'Recall'] = test_recall\n",
    "    test_results_balanced_nm.loc[nombre_modelo, 'F1'] = test_f1\n",
    "    test_results_balanced_nm.loc[nombre_modelo, 'AUC'] = test_auc\n",
    "\n",
    "print(\"Resultados de la validación cruzada con NearMiss:\")\n",
    "print(cv_results_balanced_nm)\n",
    "print(\"\\nResultados de la evaluación con NearMiss:\")\n",
    "print(test_results_balanced_nm)\n",
    "\n",
    "adasyn = ADASYN(random_state=123, sampling_strategy='minority')\n",
    "X_train_balanced_ad, y_train_balanced_ad = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "cv_results_balanced_ad = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    y_pred = np.zeros(y_train_balanced_ad.shape)\n",
    "    y_proba = np.zeros((y_train_balanced_ad.shape[0], 2))\n",
    "    for train_index, val_index in skf.split(X_train_balanced_ad, y_train_balanced_ad):\n",
    "        X_train_fold, X_val_fold = X_train_balanced_ad.iloc[train_index], X_train_balanced_ad.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_balanced_ad.iloc[train_index], y_train_balanced_ad.iloc[val_index]\n",
    "        modelo.fit(X_train_fold, y_train_fold)\n",
    "        y_pred[val_index] = modelo.predict(X_val_fold)\n",
    "        y_proba[val_index] = modelo.predict_proba(X_val_fold)\n",
    "    accuracy = metrics.accuracy_score(y_train_balanced_ad, y_pred)\n",
    "    precision = metrics.precision_score(y_train_balanced_ad, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_train_balanced_ad, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_train_balanced_ad, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_train_balanced_ad, y_proba[:, 1])\n",
    "    cv_results_balanced_ad.loc[nombre_modelo, 'Accuracy'] = accuracy\n",
    "    cv_results_balanced_ad.loc[nombre_modelo, 'Precision'] = precision\n",
    "    cv_results_balanced_ad.loc[nombre_modelo, 'Recall'] = recall\n",
    "    cv_results_balanced_ad.loc[nombre_modelo, 'F1'] = f1\n",
    "    cv_results_balanced_ad.loc[nombre_modelo, 'AUC'] = auc\n",
    "\n",
    "test_results_balanced_ad = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    modelo.fit(X_train_balanced_ad, y_train_balanced_ad)\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = metrics.precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = metrics.recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = metrics.f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = metrics.roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "    test_results_balanced_ad.loc[nombre_modelo, 'Accuracy'] = test_accuracy\n",
    "    test_results_balanced_ad.loc[nombre_modelo, 'Precision'] = test_precision\n",
    "    test_results_balanced_ad.loc[nombre_modelo, 'Recall'] = test_recall\n",
    "    test_results_balanced_ad.loc[nombre_modelo, 'F1'] = test_f1\n",
    "    test_results_balanced_ad.loc[nombre_modelo, 'AUC'] = test_auc\n",
    "\n",
    "print(\"Resultados de la validación cruzada con ADASYN:\")\n",
    "print(cv_results_balanced_ad)\n",
    "print(\"\\nResultados de la evaluación con ADASYN:\")\n",
    "print(test_results_balanced_ad)\n",
    "\n",
    "random_over = RandomOverSampler(random_state=123, sampling_strategy=0.5)\n",
    "X_train_oversampled, y_train_oversampled = random_over.fit_resample(X_train, y_train)\n",
    "\n",
    "random_under = RandomUnderSampler(random_state=123, sampling_strategy=0.5)\n",
    "X_train_balanced_comb, y_train_balanced_comb = random_under.fit_resample(X_train_oversampled, y_train)\n",
    "\n",
    "cv_results_balanced_comb = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    y_pred = np.zeros(y_train_balanced_comb.shape)\n",
    "    y_proba = np.zeros((y_train_balanced_comb.shape[0], 2))\n",
    "    for train_index, val_index in skf.split(X_train_balanced_comb, y_train_balanced_comb):\n",
    "        X_train_fold, X_val_fold = X_train_balanced_comb.iloc[train_index], X_train_balanced_comb.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_balanced_comb.iloc[train_index], y_train_balanced_comb.iloc[val_index]\n",
    "        modelo.fit(X_train_fold, y_train_fold)\n",
    "        y_pred[val_index] = modelo.predict(X_val_fold)\n",
    "        y_proba[val_index] = modelo.predict_proba(X_val_fold)\n",
    "    accuracy = metrics.accuracy_score(y_train_balanced_comb, y_pred)\n",
    "    precision = metrics.precision_score(y_train_balanced_comb, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_train_balanced_comb, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_train_balanced_comb, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_train_balanced_comb, y_proba[:, 1])\n",
    "    cv_results_balanced_comb.loc[nombre_modelo, 'Accuracy'] = accuracy\n",
    "    cv_results_balanced_comb.loc[nombre_modelo, 'Precision'] = precision\n",
    "    cv_results_balanced_comb.loc[nombre_modelo, 'Recall'] = recall\n",
    "    cv_results_balanced_comb.loc[nombre_modelo, 'F1'] = f1\n",
    "    cv_results_balanced_comb.loc[nombre_modelo, 'AUC'] = auc\n",
    "\n",
    "test_results_balanced_comb = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    modelo.fit(X_train_balanced_comb, y_train_balanced_comb)\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = metrics.precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = metrics.recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = metrics.f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = metrics.roc_auc_score(y_test, modelo.predict_proba(X_test)[:, 1])\n",
    "    test_results_balanced_comb.loc[nombre_modelo, 'Accuracy'] = test_accuracy\n",
    "    test_results_balanced_comb.loc[nombre_modelo, 'Precision'] = test_precision\n",
    "    test_results_balanced_comb.loc[nombre_modelo, 'Recall'] = test_recall\n",
    "    test_results_balanced_comb.loc[nombre_modelo, 'F1'] = test_f1\n",
    "    test_results_balanced_comb.loc[nombre_modelo, 'AUC'] = test_auc\n",
    "\n",
    "print(\"Resultados de la validación cruzada con combinación de random_over y random_under:\")\n",
    "print(cv_results_balanced_comb)\n",
    "print(\"\\nResultados de la evaluación con combinación de random_over y random_under:\")\n",
    "print(test_results_balanced_comb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da744b06",
   "metadata": {},
   "source": [
    "### COPILOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98399c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e1cb3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.609524  0.616667  0.466667  0.496667  0.694444\n",
      "RF  0.638095  0.733333       0.4  0.484762  0.752778\n",
      "NB  0.466667       0.3       0.1  0.146667  0.469444\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.362573  0.044643  0.714286  0.084034   0.50784\n",
      "RF  0.467836  0.053191  0.714286   0.09901  0.665505\n",
      "NB  0.748538  0.071429  0.428571  0.122449  0.663763\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.656126  0.597528  0.955158  0.735117  0.761406\n",
      "RF  0.945948  0.915756  0.984211  0.948039  0.994851\n",
      "NB  0.754897  0.699098  0.897053  0.785401  0.815864\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.432749  0.067308       1.0  0.126126  0.830139\n",
      "RF  0.894737  0.238095  0.714286  0.357143  0.844512\n",
      "NB   0.54386  0.050633  0.571429  0.093023  0.632404\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.677193  0.687013  0.126316  0.203222  0.745118\n",
      "RF  0.989474  0.969744       1.0  0.984549  0.999342\n",
      "NB  0.650877  0.485061  0.726316  0.581063   0.74813\n",
      "    Accuracy Precision    Recall        F1       AUC\n",
      "SV  0.923977     0.125  0.142857  0.133333  0.662892\n",
      "RF  0.947368  0.416667  0.714286  0.526316  0.902439\n",
      "NB  0.561404  0.052632  0.571429  0.096386  0.691638\n"
     ]
    }
   ],
   "source": [
    "nearmiss = NearMiss(sampling_strategy='majority')\n",
    "X_resampled_nm, y_resampled_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cv_results_balanced_nm = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "def metricas(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=skf, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=skf, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=skf, scoring='f1').mean()\n",
    "    auc = cross_val_score(model, X, y, cv=skf, scoring='roc_auc').mean()\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "svc_model = SVC(C=15, kernel='poly', degree=2, random_state=123)\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=123, max_samples=0.8, max_features='log2')\n",
    "nb_model = BernoulliNB(class_prior=[0.5, 0.5])\n",
    "cv_results_balanced_nm.loc['SV'] = metricas(svc_model, X_resampled_nm, y_resampled_nm)\n",
    "cv_results_balanced_nm.loc['RF'] = metricas(rf_model, X_resampled_nm, y_resampled_nm)\n",
    "cv_results_balanced_nm.loc['NB'] = metricas(nb_model, X_resampled_nm, y_resampled_nm)\n",
    "\n",
    "print(cv_results_balanced_nm)\n",
    "\n",
    "test_results_balanced_nm = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "svc_model.fit(X_resampled_nm, y_resampled_nm)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "test_results_balanced_nm.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results_balanced_nm.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_nm.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_nm.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_nm.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc_model.decision_function(X_test))\n",
    "rf_model.fit(X_resampled_nm, y_resampled_nm)\n",
    "y_pred_rfc = rf_model.predict(X_test)\n",
    "test_results_balanced_nm.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results_balanced_nm.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_nm.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_nm.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_nm.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "nb_model.fit(X_resampled_nm, y_resampled_nm)\n",
    "y_pred_nbc = nb_model.predict(X_test)\n",
    "test_results_balanced_nm.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results_balanced_nm.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_nm.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_nm.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_nm.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(test_results_balanced_nm)\n",
    "\n",
    "\n",
    "adasyn = ADASYN(random_state=123, sampling_strategy='minority')\n",
    "X_resampled_ad, y_resampled_ad = adasyn.fit_resample(X_train, y_train)\n",
    "cv_results_balanced_ad = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "cv_results_balanced_ad.loc['SV'] = metricas(svc_model, X_resampled_ad, y_resampled_ad)\n",
    "cv_results_balanced_ad.loc['RF'] = metricas(rf_model, X_resampled_ad, y_resampled_ad)\n",
    "cv_results_balanced_ad.loc['NB'] = metricas(nb_model, X_resampled_ad, y_resampled_ad)\n",
    "\n",
    "print(cv_results_balanced_ad)\n",
    "test_results_balanced_ad = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "svc_model.fit(X_resampled_ad, y_resampled_ad)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "test_results_balanced_ad.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results_balanced_ad.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_ad.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_ad.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_ad.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc_model.decision_function(X_test))\n",
    "rf_model.fit(X_resampled_ad, y_resampled_ad)\n",
    "y_pred_rfc = rf_model.predict(X_test)\n",
    "test_results_balanced_ad.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results_balanced_ad.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_ad.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_ad.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_ad.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "nb_model.fit(X_resampled_ad, y_resampled_ad)\n",
    "y_pred_nbc = nb_model.predict(X_test)\n",
    "test_results_balanced_ad.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results_balanced_ad.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_ad.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_ad.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_ad.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(test_results_balanced_ad)\n",
    "\n",
    "\n",
    "random_over = RandomOverSampler(random_state=123, sampling_strategy=0.5)\n",
    "random_under = RandomUnderSampler(random_state=123, sampling_strategy=0.5)\n",
    "X_resampled_ros, y_resampled_ros = random_over.fit_resample(X_train, y_train)\n",
    "X_resampled_comb, y_resampled_comb = random_under.fit_resample(X_resampled_ros, y_resampled_ros)\n",
    "cv_results_balanced_comb = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "cv_results_balanced_comb.loc['SV'] = metricas(svc_model, X_resampled_comb, y_resampled_comb)\n",
    "cv_results_balanced_comb.loc['RF'] = metricas(rf_model, X_resampled_comb, y_resampled_comb)\n",
    "cv_results_balanced_comb.loc['NB'] = metricas(nb_model, X_resampled_comb, y_resampled_comb)\n",
    "\n",
    "print(cv_results_balanced_comb)\n",
    "\n",
    "test_results_balanced_comb = pd.DataFrame(index=['SV', 'RF', 'NB'], columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "svc_model.fit(X_resampled_comb, y_resampled_comb)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "test_results_balanced_comb.loc['SV', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "test_results_balanced_comb.loc['SV', 'Precision'] = metrics.precision_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_comb.loc['SV', 'Recall'] = metrics.recall_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_comb.loc['SV', 'F1'] = metrics.f1_score(y_test, y_pred_svc, zero_division=0)\n",
    "test_results_balanced_comb.loc['SV', 'AUC'] = metrics.roc_auc_score(y_test, svc_model.decision_function(X_test))\n",
    "rf_model.fit(X_resampled_comb, y_resampled_comb)\n",
    "y_pred_rfc = rf_model.predict(X_test)\n",
    "test_results_balanced_comb.loc['RF', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "test_results_balanced_comb.loc['RF', 'Precision'] = metrics.precision_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_comb.loc['RF', 'Recall'] = metrics.recall_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_comb.loc['RF', 'F1'] = metrics.f1_score(y_test, y_pred_rfc, zero_division=0)\n",
    "test_results_balanced_comb.loc['RF', 'AUC'] = metrics.roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "nb_model.fit(X_resampled_comb, y_resampled_comb)\n",
    "y_pred_nbc = nb_model.predict(X_test)\n",
    "test_results_balanced_comb.loc['NB', 'Accuracy'] = metrics.accuracy_score(y_test, y_pred_nbc)\n",
    "test_results_balanced_comb.loc['NB', 'Precision'] = metrics.precision_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_comb.loc['NB', 'Recall'] = metrics.recall_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_comb.loc['NB', 'F1'] = metrics.f1_score(y_test, y_pred_nbc, zero_division=0)\n",
    "test_results_balanced_comb.loc['NB', 'AUC'] = metrics.roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(test_results_balanced_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754b6fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b2387ad9eb0a40e54a8889cd9718533",
     "grade": true,
     "grade_id": "cell-3f130f414f9941cc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P8: NearMiss (se comparan los valores de las matrices cv_results_balanced_nm y test_results_balanced_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698342b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2187bf7c8d7638ceab9b2a6262237851",
     "grade": true,
     "grade_id": "cell-4d944cd276a57e79",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 2 - P8: ADASYN (se comparan los valores de las matrices cv_results_balanced_ad y test_results_balanced_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d3a99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3988afd5a7fa6747d6924aa4616ec13e",
     "grade": true,
     "grade_id": "cell-d94b22ccaaa7fd50",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 3 - P8: Combinación de técnicas oversampling y undersampling (se comparan los valores de las matrices cv_results_balanced_comb y test_results_balanced_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147f23f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbe0a1ea37d754d8881a960067dd1802",
     "grade": false,
     "grade_id": "cell-629e9d0e2b899353",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "9. Considerando los resultados obtenidos desde el punto 6 hasta el punto 8 (técnicas de balance de datos), ¿cuál es la mejor técnica de balanceo de datos para este problema? Para responder esta pregunta considere solamente la métrica de desempeño `F1-Score` en el dataset de entrenamiento. \n",
    "\n",
    "El nombre del modelo dede ser `best_model_balancing` con una de las siguientes opciones: 'SV', 'RF', 'NB'. Por ejemplo:`best_model_balancing='SV'`.\n",
    "\n",
    "Además, debe entregar un objeto de tipo `int` con el nombre `best_balancing` que contenga la codificación correspondiente a la mejor técnica de balanceo de datos según la siguiente tabla:\n",
    "\n",
    "|Técnica|Código|\n",
    "|-------|------|\n",
    "|RandomOverSampler|1|\n",
    "|RandomUnderSampler|2|\n",
    "|NearMiss|3|\n",
    "|ADASYN|4|\n",
    "|Combinación de RandomOverSampler y RandomUnderSampler|5|\n",
    "\n",
    "Por ejemplo: `best_balancing=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24212b7e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d143cb4c2408f85feb29a0b633facdf",
     "grade": false,
     "grade_id": "cell-e109f56e00cf5f57",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_model_balancing = None    # Objeto que debe modificar\n",
    "best_balancing = None          # Objeto que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_balancing = 'RF'\n",
    "best_balancing = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a1372",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "175baad3060da112b90118543e21c1d9",
     "grade": true,
     "grade_id": "cell-5a844abf620db435",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411c0d2",
   "metadata": {},
   "source": [
    "10. Considerando los resultados obtenidos desde el punto 6 hasta el punto 8 (técnicas de balance de datos), ¿cuál es la mejor técnica de balanceo de datos para este problema? Para responder esta pregunta considere solamente la métrica de desempeño `F1-Score` en el dataset de test. (Esta comparación es solo confines de comprender la diferencia entre los errores cometidos en la muestra train y test, no se debe seleccionar el modelo desde la muestra test) \n",
    "\n",
    "El nombre del modelo dede ser `best_model_balancing_tets` con una de las siguientes opciones: 'SV', 'RF', 'NB'. Por ejemplo:`best_model_balancing_test='SV'`.\n",
    "\n",
    "Además, debe entregar un objeto de tipo `int` con el nombre `best_balancing_test` que contenga la codificación correspondiente a la mejor técnica de balanceo de datos según la siguiente tabla:\n",
    "\n",
    "|Técnica|Código|\n",
    "|-------|------|\n",
    "|RandomOverSampler|1|\n",
    "|RandomUnderSampler|2|\n",
    "|NearMiss|3|\n",
    "|ADASYN|4|\n",
    "|Combinación de RandomOverSampler y RandomUnderSampler|5|\n",
    "\n",
    "Por ejemplo: `best_balancing_test=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0561d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc0101617082bc89a3f7272e8f449b71",
     "grade": false,
     "grade_id": "cell-b9bbcdcb6241b952",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_model_balancing_test = None    # Objeto que debe modificar\n",
    "best_balancing_test = None          # Objeto que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84e0337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_balancing_test = 'RF'\n",
    "best_balancing_test = 4  # ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48e2d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "920b5b4fd1fe4fabc622e2ff9260b2bb",
     "grade": true,
     "grade_id": "cell-e641df2327424fd2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555119b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15edc8e8124a15c32e9a430b56b15f80",
     "grade": false,
     "grade_id": "cell-46cad04b5e8bebe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "11. Por último, responda las siguientes preguntas, en ambas considere como métrica el `F1-Score`:\n",
    "\n",
    "a. El mejor método (modelo de clasificación y técnica de balanceo) con la muestra de entrenamiento coincide con el mejor de la muestra test. Para esto, el objeto `resp_a` debe contener algunas de las siguientes:\n",
    "- 'Los métodos coinciden'\n",
    "- 'Los métodos coinciden solo en el modelo pero no en la técnica de balanceo'\n",
    "- 'Los métodos coinciden solo en la técnica de balanceo pero no en el modelo'\n",
    "- 'Los métodos no coinciden'\n",
    "\n",
    "Por ejemplo: `resp_a='Los métodos coinciden'`\n",
    "\n",
    "b. ¿Cuál de las dos métodologias, utilizando los datos originales o utilizando los datos balanceados, tiene mejor generalización en la muestra test. Para esto, el objeto `resp_b` debe contener algunas de las siguientes:\n",
    "- 'Los métodos tienen prácticamente la misma generalización, es decir, la diferencia es menor a un 1%'\n",
    "- 'Utilizando los datos originales tiene mejores resultados'\n",
    "- 'Utilizando los datos balanceados tiene mejores resultados'\n",
    "\n",
    "Por ejemplo: `resp_b='Los métodos tienen prácticamente la misma generalización, es decir, la diferencia es menor a un 1%'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d74608",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e91a6182d326bb76a75015afef62c5f2",
     "grade": false,
     "grade_id": "cell-e1b9b2e9b598c830",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "resp_a = None                         # Objeto que debe modificar\n",
    "resp_b = None                         # Objeto que debe modificar\n",
    "\n",
    "# your code here\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_a = 'Los métodos coinciden'\n",
    "resp_b = 'Utilizando los datos balanceados tiene mejores resultados'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d9149",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52da4a325cfcdac3a6214a87dc89a127",
     "grade": true,
     "grade_id": "cell-29b80f5d97ca7291",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test 1 - P11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
